{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file path (os.path): d:\\ITI\\Rec_Sys_Intake_45\\project_descrption\\project\\rec_engine\\Algorithms\\ContentBased\\MovieLens.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from rec_engine.Algorithms.ContentBased.MovieLens import MovieLens\n",
    "from rec_engine.Algorithms.ContentBased.ContentKNNAlgorithm import ContentKNNAlgorithm\n",
    "from rec_engine.Algorithms.ContentBased.Evaluator import Evaluator\n",
    "from rec_engine.Algorithms.Hybrid.HybridAlgorithm import HybridAlgorithm\n",
    "from surprise import NormalPredictor\n",
    "from surprise import SVD, SVDpp\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadMovieLensData():\n",
    "    ml = MovieLens()\n",
    "    print(\"Loading movie ratings...\")\n",
    "    data = ml.loadMovieLensLatestSmall()\n",
    "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
    "    rankings = ml.getPopularityRanks()\n",
    "    return (ml, data, rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ContentKNNAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating  ContentKNN ...\n",
      "Evaluating accuracy...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  8775\n",
      "100  of  8775\n",
      "200  of  8775\n",
      "300  of  8775\n",
      "400  of  8775\n",
      "500  of  8775\n",
      "600  of  8775\n",
      "700  of  8775\n",
      "800  of  8775\n",
      "900  of  8775\n",
      "1000  of  8775\n",
      "1100  of  8775\n",
      "1200  of  8775\n",
      "1300  of  8775\n",
      "1400  of  8775\n",
      "1500  of  8775\n",
      "1600  of  8775\n",
      "1700  of  8775\n",
      "1800  of  8775\n",
      "1900  of  8775\n",
      "2000  of  8775\n",
      "2100  of  8775\n",
      "2200  of  8775\n",
      "2300  of  8775\n",
      "2400  of  8775\n",
      "2500  of  8775\n",
      "2600  of  8775\n",
      "2700  of  8775\n",
      "2800  of  8775\n",
      "2900  of  8775\n",
      "3000  of  8775\n",
      "3100  of  8775\n",
      "3200  of  8775\n",
      "3300  of  8775\n",
      "3400  of  8775\n",
      "3500  of  8775\n",
      "3600  of  8775\n",
      "3700  of  8775\n",
      "3800  of  8775\n",
      "3900  of  8775\n",
      "4000  of  8775\n",
      "4100  of  8775\n",
      "4200  of  8775\n",
      "4300  of  8775\n",
      "4400  of  8775\n",
      "4500  of  8775\n",
      "4600  of  8775\n",
      "4700  of  8775\n",
      "4800  of  8775\n",
      "4900  of  8775\n",
      "5000  of  8775\n",
      "5100  of  8775\n",
      "5200  of  8775\n",
      "5300  of  8775\n",
      "5400  of  8775\n",
      "5500  of  8775\n",
      "5600  of  8775\n",
      "5700  of  8775\n",
      "5800  of  8775\n",
      "5900  of  8775\n",
      "6000  of  8775\n",
      "6100  of  8775\n",
      "6200  of  8775\n",
      "6300  of  8775\n",
      "6400  of  8775\n",
      "6500  of  8775\n",
      "6600  of  8775\n",
      "6700  of  8775\n",
      "6800  of  8775\n",
      "6900  of  8775\n",
      "7000  of  8775\n",
      "7100  of  8775\n",
      "7200  of  8775\n",
      "7300  of  8775\n",
      "7400  of  8775\n",
      "7500  of  8775\n",
      "7600  of  8775\n",
      "7700  of  8775\n",
      "7800  of  8775\n",
      "7900  of  8775\n",
      "8000  of  8775\n",
      "8100  of  8775\n",
      "8200  of  8775\n",
      "8300  of  8775\n",
      "8400  of  8775\n",
      "8500  of  8775\n",
      "8600  of  8775\n",
      "8700  of  8775\n",
      "...done.\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  ContentKNN ...\n",
      "Evaluating accuracy...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  8775\n",
      "100  of  8775\n",
      "200  of  8775\n",
      "300  of  8775\n",
      "400  of  8775\n",
      "500  of  8775\n",
      "600  of  8775\n",
      "700  of  8775\n",
      "800  of  8775\n",
      "900  of  8775\n",
      "1000  of  8775\n",
      "1100  of  8775\n",
      "1200  of  8775\n",
      "1300  of  8775\n",
      "1400  of  8775\n",
      "1500  of  8775\n",
      "1600  of  8775\n",
      "1700  of  8775\n",
      "1800  of  8775\n",
      "1900  of  8775\n",
      "2000  of  8775\n",
      "2100  of  8775\n",
      "2200  of  8775\n",
      "2300  of  8775\n",
      "2400  of  8775\n",
      "2500  of  8775\n",
      "2600  of  8775\n",
      "2700  of  8775\n",
      "2800  of  8775\n",
      "2900  of  8775\n",
      "3000  of  8775\n",
      "3100  of  8775\n",
      "3200  of  8775\n",
      "3300  of  8775\n",
      "3400  of  8775\n",
      "3500  of  8775\n",
      "3600  of  8775\n",
      "3700  of  8775\n",
      "3800  of  8775\n",
      "3900  of  8775\n",
      "4000  of  8775\n",
      "4100  of  8775\n",
      "4200  of  8775\n",
      "4300  of  8775\n",
      "4400  of  8775\n",
      "4500  of  8775\n",
      "4600  of  8775\n",
      "4700  of  8775\n",
      "4800  of  8775\n",
      "4900  of  8775\n",
      "5000  of  8775\n",
      "5100  of  8775\n",
      "5200  of  8775\n",
      "5300  of  8775\n",
      "5400  of  8775\n",
      "5500  of  8775\n",
      "5600  of  8775\n",
      "5700  of  8775\n",
      "5800  of  8775\n",
      "5900  of  8775\n",
      "6000  of  8775\n",
      "6100  of  8775\n",
      "6200  of  8775\n",
      "6300  of  8775\n",
      "6400  of  8775\n",
      "6500  of  8775\n",
      "6600  of  8775\n",
      "6700  of  8775\n",
      "6800  of  8775\n",
      "6900  of  8775\n",
      "7000  of  8775\n",
      "7100  of  8775\n",
      "7200  of  8775\n",
      "7300  of  8775\n",
      "7400  of  8775\n",
      "7500  of  8775\n",
      "7600  of  8775\n",
      "7700  of  8775\n",
      "7800  of  8775\n",
      "7900  of  8775\n",
      "8000  of  8775\n",
      "8100  of  8775\n",
      "8200  of  8775\n",
      "8300  of  8775\n",
      "8400  of  8775\n",
      "8500  of  8775\n",
      "8600  of  8775\n",
      "8700  of  8775\n",
      "...done.\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "\n",
      "\n",
      "Algorithm  RMSE       MAE       \n",
      "ContentKNN 0.9055     0.6983    \n",
      "Random     1.4283     1.1414    \n",
      "\n",
      "Legend:\n",
      "\n",
      "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
      "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
      "\n",
      "Using recommender  ContentKNN\n",
      "\n",
      "Building recommendation model...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  9724\n",
      "100  of  9724\n",
      "200  of  9724\n",
      "300  of  9724\n",
      "400  of  9724\n",
      "500  of  9724\n",
      "600  of  9724\n",
      "700  of  9724\n",
      "800  of  9724\n",
      "900  of  9724\n",
      "1000  of  9724\n",
      "1100  of  9724\n",
      "1200  of  9724\n",
      "1300  of  9724\n",
      "1400  of  9724\n",
      "1500  of  9724\n",
      "1600  of  9724\n",
      "1700  of  9724\n",
      "1800  of  9724\n",
      "1900  of  9724\n",
      "2000  of  9724\n",
      "2100  of  9724\n",
      "2200  of  9724\n",
      "2300  of  9724\n",
      "2400  of  9724\n",
      "2500  of  9724\n",
      "2600  of  9724\n",
      "2700  of  9724\n",
      "2800  of  9724\n",
      "2900  of  9724\n",
      "3000  of  9724\n",
      "3100  of  9724\n",
      "3200  of  9724\n",
      "3300  of  9724\n",
      "3400  of  9724\n",
      "3500  of  9724\n",
      "3600  of  9724\n",
      "3700  of  9724\n",
      "3800  of  9724\n",
      "3900  of  9724\n",
      "4000  of  9724\n",
      "4100  of  9724\n",
      "4200  of  9724\n",
      "4300  of  9724\n",
      "4400  of  9724\n",
      "4500  of  9724\n",
      "4600  of  9724\n",
      "4700  of  9724\n",
      "4800  of  9724\n",
      "4900  of  9724\n",
      "5000  of  9724\n",
      "5100  of  9724\n",
      "5200  of  9724\n",
      "5300  of  9724\n",
      "5400  of  9724\n",
      "5500  of  9724\n",
      "5600  of  9724\n",
      "5700  of  9724\n",
      "5800  of  9724\n",
      "5900  of  9724\n",
      "6000  of  9724\n",
      "6100  of  9724\n",
      "6200  of  9724\n",
      "6300  of  9724\n",
      "6400  of  9724\n",
      "6500  of  9724\n",
      "6600  of  9724\n",
      "6700  of  9724\n",
      "6800  of  9724\n",
      "6900  of  9724\n",
      "7000  of  9724\n",
      "7100  of  9724\n",
      "7200  of  9724\n",
      "7300  of  9724\n",
      "7400  of  9724\n",
      "7500  of  9724\n",
      "7600  of  9724\n",
      "7700  of  9724\n",
      "7800  of  9724\n",
      "7900  of  9724\n",
      "8000  of  9724\n",
      "8100  of  9724\n",
      "8200  of  9724\n",
      "8300  of  9724\n",
      "8400  of  9724\n",
      "8500  of  9724\n",
      "8600  of  9724\n",
      "8700  of  9724\n",
      "8800  of  9724\n",
      "8900  of  9724\n",
      "9000  of  9724\n",
      "9100  of  9724\n",
      "9200  of  9724\n",
      "9300  of  9724\n",
      "9400  of  9724\n",
      "9500  of  9724\n",
      "9600  of  9724\n",
      "9700  of  9724\n",
      "...done.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Pinocchio (1940) 5\n",
      "James and the Giant Peach (1996) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Escape to Witch Mountain (1975) 5\n",
      "Winnie the Pooh and the Blustery Day (1968) 5\n",
      "Three Caballeros, The (1945) 5\n",
      "Sword in the Stone, The (1963) 5\n",
      "Pete's Dragon (1977) 5\n",
      "Bedknobs and Broomsticks (1971) 5\n",
      "Alice in Wonderland (1951) 5\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Rob Roy (1995) 5\n",
      "Desperado (1995) 5\n",
      "So I Married an Axe Murderer (1993) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Dumbo (1941) 5\n",
      "That Thing You Do! (1996) 5\n",
      "Ghost and the Darkness, The (1996) 5\n",
      "Alien (1979) 5\n",
      "Quiet Man, The (1952) 5\n",
      "Indiana Jones and the Last Crusade (1989) 5\n",
      "\n",
      "Using recommender  ContentKNN\n",
      "\n",
      "Building recommendation model...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  9724\n",
      "100  of  9724\n",
      "200  of  9724\n",
      "300  of  9724\n",
      "400  of  9724\n",
      "500  of  9724\n",
      "600  of  9724\n",
      "700  of  9724\n",
      "800  of  9724\n",
      "900  of  9724\n",
      "1000  of  9724\n",
      "1100  of  9724\n",
      "1200  of  9724\n",
      "1300  of  9724\n",
      "1400  of  9724\n",
      "1500  of  9724\n",
      "1600  of  9724\n",
      "1700  of  9724\n",
      "1800  of  9724\n",
      "1900  of  9724\n",
      "2000  of  9724\n",
      "2100  of  9724\n",
      "2200  of  9724\n",
      "2300  of  9724\n",
      "2400  of  9724\n",
      "2500  of  9724\n",
      "2600  of  9724\n",
      "2700  of  9724\n",
      "2800  of  9724\n",
      "2900  of  9724\n",
      "3000  of  9724\n",
      "3100  of  9724\n",
      "3200  of  9724\n",
      "3300  of  9724\n",
      "3400  of  9724\n",
      "3500  of  9724\n",
      "3600  of  9724\n",
      "3700  of  9724\n",
      "3800  of  9724\n",
      "3900  of  9724\n",
      "4000  of  9724\n",
      "4100  of  9724\n",
      "4200  of  9724\n",
      "4300  of  9724\n",
      "4400  of  9724\n",
      "4500  of  9724\n",
      "4600  of  9724\n",
      "4700  of  9724\n",
      "4800  of  9724\n",
      "4900  of  9724\n",
      "5000  of  9724\n",
      "5100  of  9724\n",
      "5200  of  9724\n",
      "5300  of  9724\n",
      "5400  of  9724\n",
      "5500  of  9724\n",
      "5600  of  9724\n",
      "5700  of  9724\n",
      "5800  of  9724\n",
      "5900  of  9724\n",
      "6000  of  9724\n",
      "6100  of  9724\n",
      "6200  of  9724\n",
      "6300  of  9724\n",
      "6400  of  9724\n",
      "6500  of  9724\n",
      "6600  of  9724\n",
      "6700  of  9724\n",
      "6800  of  9724\n",
      "6900  of  9724\n",
      "7000  of  9724\n",
      "7100  of  9724\n",
      "7200  of  9724\n",
      "7300  of  9724\n",
      "7400  of  9724\n",
      "7500  of  9724\n",
      "7600  of  9724\n",
      "7700  of  9724\n",
      "7800  of  9724\n",
      "7900  of  9724\n",
      "8000  of  9724\n",
      "8100  of  9724\n",
      "8200  of  9724\n",
      "8300  of  9724\n",
      "8400  of  9724\n",
      "8500  of  9724\n",
      "8600  of  9724\n",
      "8700  of  9724\n",
      "8800  of  9724\n",
      "8900  of  9724\n",
      "9000  of  9724\n",
      "9100  of  9724\n",
      "9200  of  9724\n",
      "9300  of  9724\n",
      "9400  of  9724\n",
      "9500  of  9724\n",
      "9600  of  9724\n",
      "9700  of  9724\n",
      "...done.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Pinocchio (1940) 5\n",
      "James and the Giant Peach (1996) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Escape to Witch Mountain (1975) 5\n",
      "Winnie the Pooh and the Blustery Day (1968) 5\n",
      "Three Caballeros, The (1945) 5\n",
      "Sword in the Stone, The (1963) 5\n",
      "Pete's Dragon (1977) 5\n",
      "Bedknobs and Broomsticks (1971) 5\n",
      "Alice in Wonderland (1951) 5\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Full Metal Jacket (1987) 5\n",
      "Sneakers (1992) 5\n",
      "Newton Boys, The (1998) 5\n",
      "Psycho (1998) 5\n",
      "Dick Tracy (1990) 5\n",
      "Superman II (1980) 5\n",
      "Frankenstein (1931) 5\n",
      "Who Framed Roger Rabbit? (1988) 5\n",
      "Live and Let Die (1973) 5\n",
      "Green Mile, The (1999) 5\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Load up common data set for the recommender algorithms\n",
    "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
    "\n",
    "# Construct an Evaluator to, you know, evaluate them\n",
    "evaluator = Evaluator(evaluationData, rankings)\n",
    "\n",
    "contentKNN = ContentKNNAlgorithm()\n",
    "evaluator.AddAlgorithm(contentKNN, \"ContentKNN\")\n",
    "\n",
    "# Just make random recommendations\n",
    "Random = NormalPredictor()\n",
    "evaluator.AddAlgorithm(Random, \"Random\")\n",
    "\n",
    "evaluator.Evaluate(False)\n",
    "\n",
    "evaluator.SampleTopNRecs(ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Result\n",
    "| Algorithm   | RMSE    | MAE     |\n",
    "|-------------|---------|---------|\n",
    "| ContentKNN | 0.9055  | 0.6983  |\n",
    "| Random     | 1.4283  | 1.1414  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SVD & SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating  ContentKNN ...\n",
      "Evaluating accuracy...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  8775\n",
      "100  of  8775\n",
      "200  of  8775\n",
      "300  of  8775\n",
      "400  of  8775\n",
      "500  of  8775\n",
      "600  of  8775\n",
      "700  of  8775\n",
      "800  of  8775\n",
      "900  of  8775\n",
      "1000  of  8775\n",
      "1100  of  8775\n",
      "1200  of  8775\n",
      "1300  of  8775\n",
      "1400  of  8775\n",
      "1500  of  8775\n",
      "1600  of  8775\n",
      "1700  of  8775\n",
      "1800  of  8775\n",
      "1900  of  8775\n",
      "2000  of  8775\n",
      "2100  of  8775\n",
      "2200  of  8775\n",
      "2300  of  8775\n",
      "2400  of  8775\n",
      "2500  of  8775\n",
      "2600  of  8775\n",
      "2700  of  8775\n",
      "2800  of  8775\n",
      "2900  of  8775\n",
      "3000  of  8775\n",
      "3100  of  8775\n",
      "3200  of  8775\n",
      "3300  of  8775\n",
      "3400  of  8775\n",
      "3500  of  8775\n",
      "3600  of  8775\n",
      "3700  of  8775\n",
      "3800  of  8775\n",
      "3900  of  8775\n",
      "4000  of  8775\n",
      "4100  of  8775\n",
      "4200  of  8775\n",
      "4300  of  8775\n",
      "4400  of  8775\n",
      "4500  of  8775\n",
      "4600  of  8775\n",
      "4700  of  8775\n",
      "4800  of  8775\n",
      "4900  of  8775\n",
      "5000  of  8775\n",
      "5100  of  8775\n",
      "5200  of  8775\n",
      "5300  of  8775\n",
      "5400  of  8775\n",
      "5500  of  8775\n",
      "5600  of  8775\n",
      "5700  of  8775\n",
      "5800  of  8775\n",
      "5900  of  8775\n",
      "6000  of  8775\n",
      "6100  of  8775\n",
      "6200  of  8775\n",
      "6300  of  8775\n",
      "6400  of  8775\n",
      "6500  of  8775\n",
      "6600  of  8775\n",
      "6700  of  8775\n",
      "6800  of  8775\n",
      "6900  of  8775\n",
      "7000  of  8775\n",
      "7100  of  8775\n",
      "7200  of  8775\n",
      "7300  of  8775\n",
      "7400  of  8775\n",
      "7500  of  8775\n",
      "7600  of  8775\n",
      "7700  of  8775\n",
      "7800  of  8775\n",
      "7900  of  8775\n",
      "8000  of  8775\n",
      "8100  of  8775\n",
      "8200  of  8775\n",
      "8300  of  8775\n",
      "8400  of  8775\n",
      "8500  of  8775\n",
      "8600  of  8775\n",
      "8700  of  8775\n",
      "...done.\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  ContentKNN ...\n",
      "Evaluating accuracy...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  8775\n",
      "100  of  8775\n",
      "200  of  8775\n",
      "300  of  8775\n",
      "400  of  8775\n",
      "500  of  8775\n",
      "600  of  8775\n",
      "700  of  8775\n",
      "800  of  8775\n",
      "900  of  8775\n",
      "1000  of  8775\n",
      "1100  of  8775\n",
      "1200  of  8775\n",
      "1300  of  8775\n",
      "1400  of  8775\n",
      "1500  of  8775\n",
      "1600  of  8775\n",
      "1700  of  8775\n",
      "1800  of  8775\n",
      "1900  of  8775\n",
      "2000  of  8775\n",
      "2100  of  8775\n",
      "2200  of  8775\n",
      "2300  of  8775\n",
      "2400  of  8775\n",
      "2500  of  8775\n",
      "2600  of  8775\n",
      "2700  of  8775\n",
      "2800  of  8775\n",
      "2900  of  8775\n",
      "3000  of  8775\n",
      "3100  of  8775\n",
      "3200  of  8775\n",
      "3300  of  8775\n",
      "3400  of  8775\n",
      "3500  of  8775\n",
      "3600  of  8775\n",
      "3700  of  8775\n",
      "3800  of  8775\n",
      "3900  of  8775\n",
      "4000  of  8775\n",
      "4100  of  8775\n",
      "4200  of  8775\n",
      "4300  of  8775\n",
      "4400  of  8775\n",
      "4500  of  8775\n",
      "4600  of  8775\n",
      "4700  of  8775\n",
      "4800  of  8775\n",
      "4900  of  8775\n",
      "5000  of  8775\n",
      "5100  of  8775\n",
      "5200  of  8775\n",
      "5300  of  8775\n",
      "5400  of  8775\n",
      "5500  of  8775\n",
      "5600  of  8775\n",
      "5700  of  8775\n",
      "5800  of  8775\n",
      "5900  of  8775\n",
      "6000  of  8775\n",
      "6100  of  8775\n",
      "6200  of  8775\n",
      "6300  of  8775\n",
      "6400  of  8775\n",
      "6500  of  8775\n",
      "6600  of  8775\n",
      "6700  of  8775\n",
      "6800  of  8775\n",
      "6900  of  8775\n",
      "7000  of  8775\n",
      "7100  of  8775\n",
      "7200  of  8775\n",
      "7300  of  8775\n",
      "7400  of  8775\n",
      "7500  of  8775\n",
      "7600  of  8775\n",
      "7700  of  8775\n",
      "7800  of  8775\n",
      "7900  of  8775\n",
      "8000  of  8775\n",
      "8100  of  8775\n",
      "8200  of  8775\n",
      "8300  of  8775\n",
      "8400  of  8775\n",
      "8500  of  8775\n",
      "8600  of  8775\n",
      "8700  of  8775\n",
      "...done.\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  SVD ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  SVD++ ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "\n",
      "\n",
      "Algorithm  RMSE       MAE       \n",
      "ContentKNN 0.9055     0.6983    \n",
      "Random     1.4265     1.1400    \n",
      "SVD        0.8774     0.6741    \n",
      "SVD++      0.8721     0.6669    \n",
      "\n",
      "Legend:\n",
      "\n",
      "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
      "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
      "\n",
      "Using recommender  ContentKNN\n",
      "\n",
      "Building recommendation model...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  9724\n",
      "100  of  9724\n",
      "200  of  9724\n",
      "300  of  9724\n",
      "400  of  9724\n",
      "500  of  9724\n",
      "600  of  9724\n",
      "700  of  9724\n",
      "800  of  9724\n",
      "900  of  9724\n",
      "1000  of  9724\n",
      "1100  of  9724\n",
      "1200  of  9724\n",
      "1300  of  9724\n",
      "1400  of  9724\n",
      "1500  of  9724\n",
      "1600  of  9724\n",
      "1700  of  9724\n",
      "1800  of  9724\n",
      "1900  of  9724\n",
      "2000  of  9724\n",
      "2100  of  9724\n",
      "2200  of  9724\n",
      "2300  of  9724\n",
      "2400  of  9724\n",
      "2500  of  9724\n",
      "2600  of  9724\n",
      "2700  of  9724\n",
      "2800  of  9724\n",
      "2900  of  9724\n",
      "3000  of  9724\n",
      "3100  of  9724\n",
      "3200  of  9724\n",
      "3300  of  9724\n",
      "3400  of  9724\n",
      "3500  of  9724\n",
      "3600  of  9724\n",
      "3700  of  9724\n",
      "3800  of  9724\n",
      "3900  of  9724\n",
      "4000  of  9724\n",
      "4100  of  9724\n",
      "4200  of  9724\n",
      "4300  of  9724\n",
      "4400  of  9724\n",
      "4500  of  9724\n",
      "4600  of  9724\n",
      "4700  of  9724\n",
      "4800  of  9724\n",
      "4900  of  9724\n",
      "5000  of  9724\n",
      "5100  of  9724\n",
      "5200  of  9724\n",
      "5300  of  9724\n",
      "5400  of  9724\n",
      "5500  of  9724\n",
      "5600  of  9724\n",
      "5700  of  9724\n",
      "5800  of  9724\n",
      "5900  of  9724\n",
      "6000  of  9724\n",
      "6100  of  9724\n",
      "6200  of  9724\n",
      "6300  of  9724\n",
      "6400  of  9724\n",
      "6500  of  9724\n",
      "6600  of  9724\n",
      "6700  of  9724\n",
      "6800  of  9724\n",
      "6900  of  9724\n",
      "7000  of  9724\n",
      "7100  of  9724\n",
      "7200  of  9724\n",
      "7300  of  9724\n",
      "7400  of  9724\n",
      "7500  of  9724\n",
      "7600  of  9724\n",
      "7700  of  9724\n",
      "7800  of  9724\n",
      "7900  of  9724\n",
      "8000  of  9724\n",
      "8100  of  9724\n",
      "8200  of  9724\n",
      "8300  of  9724\n",
      "8400  of  9724\n",
      "8500  of  9724\n",
      "8600  of  9724\n",
      "8700  of  9724\n",
      "8800  of  9724\n",
      "8900  of  9724\n",
      "9000  of  9724\n",
      "9100  of  9724\n",
      "9200  of  9724\n",
      "9300  of  9724\n",
      "9400  of  9724\n",
      "9500  of  9724\n",
      "9600  of  9724\n",
      "9700  of  9724\n",
      "...done.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Pinocchio (1940) 5\n",
      "James and the Giant Peach (1996) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Escape to Witch Mountain (1975) 5\n",
      "Winnie the Pooh and the Blustery Day (1968) 5\n",
      "Three Caballeros, The (1945) 5\n",
      "Sword in the Stone, The (1963) 5\n",
      "Pete's Dragon (1977) 5\n",
      "Bedknobs and Broomsticks (1971) 5\n",
      "Alice in Wonderland (1951) 5\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Toy Story (1995) 5\n",
      "Billy Madison (1995) 5\n",
      "Tombstone (1993) 5\n",
      "Mr. Smith Goes to Washington (1939) 5\n",
      "Ghost and the Darkness, The (1996) 5\n",
      "Platoon (1986) 5\n",
      "Princess Bride, The (1987) 5\n",
      "Blues Brothers, The (1980) 5\n",
      "Best Men (1997) 5\n",
      "Men in Black (a.k.a. MIB) (1997) 5\n",
      "\n",
      "Using recommender  ContentKNN\n",
      "\n",
      "Building recommendation model...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  9724\n",
      "100  of  9724\n",
      "200  of  9724\n",
      "300  of  9724\n",
      "400  of  9724\n",
      "500  of  9724\n",
      "600  of  9724\n",
      "700  of  9724\n",
      "800  of  9724\n",
      "900  of  9724\n",
      "1000  of  9724\n",
      "1100  of  9724\n",
      "1200  of  9724\n",
      "1300  of  9724\n",
      "1400  of  9724\n",
      "1500  of  9724\n",
      "1600  of  9724\n",
      "1700  of  9724\n",
      "1800  of  9724\n",
      "1900  of  9724\n",
      "2000  of  9724\n",
      "2100  of  9724\n",
      "2200  of  9724\n",
      "2300  of  9724\n",
      "2400  of  9724\n",
      "2500  of  9724\n",
      "2600  of  9724\n",
      "2700  of  9724\n",
      "2800  of  9724\n",
      "2900  of  9724\n",
      "3000  of  9724\n",
      "3100  of  9724\n",
      "3200  of  9724\n",
      "3300  of  9724\n",
      "3400  of  9724\n",
      "3500  of  9724\n",
      "3600  of  9724\n",
      "3700  of  9724\n",
      "3800  of  9724\n",
      "3900  of  9724\n",
      "4000  of  9724\n",
      "4100  of  9724\n",
      "4200  of  9724\n",
      "4300  of  9724\n",
      "4400  of  9724\n",
      "4500  of  9724\n",
      "4600  of  9724\n",
      "4700  of  9724\n",
      "4800  of  9724\n",
      "4900  of  9724\n",
      "5000  of  9724\n",
      "5100  of  9724\n",
      "5200  of  9724\n",
      "5300  of  9724\n",
      "5400  of  9724\n",
      "5500  of  9724\n",
      "5600  of  9724\n",
      "5700  of  9724\n",
      "5800  of  9724\n",
      "5900  of  9724\n",
      "6000  of  9724\n",
      "6100  of  9724\n",
      "6200  of  9724\n",
      "6300  of  9724\n",
      "6400  of  9724\n",
      "6500  of  9724\n",
      "6600  of  9724\n",
      "6700  of  9724\n",
      "6800  of  9724\n",
      "6900  of  9724\n",
      "7000  of  9724\n",
      "7100  of  9724\n",
      "7200  of  9724\n",
      "7300  of  9724\n",
      "7400  of  9724\n",
      "7500  of  9724\n",
      "7600  of  9724\n",
      "7700  of  9724\n",
      "7800  of  9724\n",
      "7900  of  9724\n",
      "8000  of  9724\n",
      "8100  of  9724\n",
      "8200  of  9724\n",
      "8300  of  9724\n",
      "8400  of  9724\n",
      "8500  of  9724\n",
      "8600  of  9724\n",
      "8700  of  9724\n",
      "8800  of  9724\n",
      "8900  of  9724\n",
      "9000  of  9724\n",
      "9100  of  9724\n",
      "9200  of  9724\n",
      "9300  of  9724\n",
      "9400  of  9724\n",
      "9500  of  9724\n",
      "9600  of  9724\n",
      "9700  of  9724\n",
      "...done.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Pinocchio (1940) 5\n",
      "James and the Giant Peach (1996) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Escape to Witch Mountain (1975) 5\n",
      "Winnie the Pooh and the Blustery Day (1968) 5\n",
      "Three Caballeros, The (1945) 5\n",
      "Sword in the Stone, The (1963) 5\n",
      "Pete's Dragon (1977) 5\n",
      "Bedknobs and Broomsticks (1971) 5\n",
      "Alice in Wonderland (1951) 5\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Pulp Fiction (1994) 5\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) 5\n",
      "Fantasia (1940) 5\n",
      "L.A. Confidential (1997) 5\n",
      "Rocky (1976) 5\n",
      "Lord of the Rings, The (1978) 5\n",
      "Rush Hour (1998) 5\n",
      "Young Sherlock Holmes (1985) 5\n",
      "Planet of the Apes (1968) 5\n",
      "Superman (1978) 5\n",
      "\n",
      "Using recommender  SVD\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Departed, The (2006) 4.498088219495752\n",
      "Forrest Gump (1994) 4.490426072205098\n",
      "Blade Runner (1982) 4.47149394276547\n",
      "Amelie (Fabuleux destin d'AmÃ©lie Poulain, Le) (2001) 4.470090796702887\n",
      "Shawshank Redemption, The (1994) 4.443548745851059\n",
      "Life Is Beautiful (La Vita Ã¨ bella) (1997) 4.431880429994463\n",
      "Lawrence of Arabia (1962) 4.421315466712338\n",
      "Citizen Kane (1941) 4.4112815934858\n",
      "Wallace & Gromit: The Best of Aardman Animation (1996) 4.406135068976476\n",
      "Godfather: Part II, The (1974) 4.390440222358744\n",
      "\n",
      "Using recommender  SVD++\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Star Wars: Episode IV - A New Hope (1977) 4.746520598501638\n",
      "Casablanca (1942) 4.724894143759636\n",
      "Shawshank Redemption, The (1994) 4.674527918094885\n",
      "Great Escape, The (1963) 4.533661989061435\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) 4.509454410841635\n",
      "Bridge on the River Kwai, The (1957) 4.504173829510304\n",
      "Apocalypse Now (1979) 4.4903870913611295\n",
      "Godfather, The (1972) 4.47654720438724\n",
      "Grand Day Out with Wallace and Gromit, A (1989) 4.416058694574412\n",
      "Fugitive, The (1993) 4.414391989595168\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "From Dusk Till Dawn (1996) 5\n",
      "Pulp Fiction (1994) 5\n",
      "Clear and Present Danger (1994) 5\n",
      "Ghost and Mrs. Muir, The (1947) 5\n",
      "Monty Python's Life of Brian (1979) 5\n",
      "Clockwork Orange, A (1971) 5\n",
      "Full Metal Jacket (1987) 5\n",
      "Groundhog Day (1993) 5\n",
      "Austin Powers: International Man of Mystery (1997) 5\n",
      "Face/Off (1997) 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Load up common data set for the recommender algorithms\n",
    "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
    "\n",
    "# Construct an Evaluator to, you know, evaluate them\n",
    "evaluator = Evaluator(evaluationData, rankings)\n",
    "\n",
    "# SVD\n",
    "SVD = SVD()\n",
    "evaluator.AddAlgorithm(SVD, \"SVD\")\n",
    "\n",
    "# SVD++\n",
    "SVDPlusPlus = SVDpp()\n",
    "evaluator.AddAlgorithm(SVDPlusPlus, \"SVD++\")\n",
    "\n",
    "# Just make random recommendations\n",
    "Random = NormalPredictor()\n",
    "evaluator.AddAlgorithm(Random, \"Random\")\n",
    "\n",
    "# Fight!\n",
    "evaluator.Evaluate(False)\n",
    "\n",
    "evaluator.SampleTopNRecs(ml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Result\n",
    "| Algorithm   | RMSE    | MAE     |\n",
    "|-------------|---------|---------|\n",
    "| ContentKNN  | 0.9055  | 0.6983  |\n",
    "| Random      | 1.4265  | 1.1400  |\n",
    "| SVD         | 0.8774  | 0.6741  |\n",
    "| SVD++       | 0.8721  | 0.6669  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the sdv to get lower error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n",
      "Searching for best parameters...\n",
      "Best RMSE score attained:  0.8716561680357514\n",
      "{'n_epochs': 20, 'lr_all': 0.005, 'n_factors': 20}\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating  SVD - Tuned ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  SVD - Untuned ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "\n",
      "\n",
      "Algorithm  RMSE       MAE       \n",
      "SVD - Tuned 0.8756     0.6719    \n",
      "SVD - Untuned 0.8809     0.6758    \n",
      "Random     1.4279     1.1386    \n",
      "\n",
      "Legend:\n",
      "\n",
      "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
      "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
      "\n",
      "Using recommender  SVD - Tuned\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964) 4.582104168890538\n",
      "Pulp Fiction (1994) 4.532733642381384\n",
      "Shawshank Redemption, The (1994) 4.520386455954097\n",
      "Eternal Sunshine of the Spotless Mind (2004) 4.517225794535145\n",
      "American Beauty (1999) 4.480903132983273\n",
      "Amelie (Fabuleux destin d'AmÃ©lie Poulain, Le) (2001) 4.479465259910029\n",
      "Rear Window (1954) 4.47412871312906\n",
      "Usual Suspects, The (1995) 4.472304193096288\n",
      "Casablanca (1942) 4.465739785281471\n",
      "Monty Python and the Holy Grail (1975) 4.460806260257845\n",
      "\n",
      "Using recommender  SVD - Untuned\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "There Will Be Blood (2007) 4.7255585083310425\n",
      "Princess Bride, The (1987) 4.509339593086544\n",
      "Shawshank Redemption, The (1994) 4.484499722275683\n",
      "Forrest Gump (1994) 4.47257688565397\n",
      "Finding Nemo (2003) 4.469128605152999\n",
      "Sunset Blvd. (a.k.a. Sunset Boulevard) (1950) 4.467672640102127\n",
      "Casablanca (1942) 4.459271966326456\n",
      "Boondock Saints, The (2000) 4.450842253696638\n",
      "American History X (1998) 4.439043014027791\n",
      "High Noon (1952) 4.421262947011693\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "From Dusk Till Dawn (1996) 5\n",
      "Mask, The (1994) 5\n",
      "Winnie the Pooh and the Blustery Day (1968) 5\n",
      "I Know What You Did Last Summer (1997) 5\n",
      "Saving Private Ryan (1998) 5\n",
      "American Tail, An (1986) 5\n",
      "Legend (1985) 5\n",
      "Beetlejuice (1988) 5\n",
      "Texas Chainsaw Massacre, The (1974) 5\n",
      "Excalibur (1981) 5\n"
     ]
    }
   ],
   "source": [
    "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
    "\n",
    "print(\"Searching for best parameters...\")\n",
    "param_grid = {'n_epochs': [10,20,], 'lr_all': [0.001,0.005],\n",
    "              'n_factors': [20,50]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=4)\n",
    "\n",
    "gs.fit(evaluationData)\n",
    "\n",
    "# best RMSE score\n",
    "print(\"Best RMSE score attained: \", gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# Construct an Evaluator to, you know, evaluate them\n",
    "evaluator = Evaluator(evaluationData, rankings)\n",
    "\n",
    "params = gs.best_params['rmse']\n",
    "SVDtuned = SVD(n_epochs = params['n_epochs'], lr_all = params['lr_all'], n_factors = params['n_factors'])\n",
    "evaluator.AddAlgorithm(SVDtuned, \"SVD - Tuned\")\n",
    "\n",
    "SVDUntuned = SVD()\n",
    "evaluator.AddAlgorithm(SVDUntuned, \"SVD - Untuned\")\n",
    "\n",
    "# Just make random recommendations\n",
    "Random = NormalPredictor()\n",
    "evaluator.AddAlgorithm(Random, \"Random\")\n",
    "\n",
    "# Fight!\n",
    "evaluator.Evaluate(False)\n",
    "\n",
    "evaluator.SampleTopNRecs(ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Item-based KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating  Item KNN ...\n",
      "Evaluating accuracy...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  Item KNN ...\n",
      "Evaluating accuracy...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "\n",
      "\n",
      "Algorithm  RMSE       MAE       \n",
      "Item KNN   0.9788     0.7610    \n",
      "Random     1.4283     1.1414    \n",
      "\n",
      "Legend:\n",
      "\n",
      "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
      "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
      "\n",
      "Using recommender  Item KNN\n",
      "\n",
      "Building recommendation model...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Best Men (1997) 5\n",
      "Galaxy of Terror (Quest) (1981) 5\n",
      "Looker (1981) 5\n",
      "Android (1982) 5\n",
      "Alien Contamination (1980) 5\n",
      "Master of the Flying Guillotine (Du bi quan wang da po xue di zi) (1975) 5\n",
      "Priceless (Hors de prix) (2006) 5\n",
      "Lassie (1994) 5\n",
      "Act of Valor (2012) 5\n",
      "Honey (2003) 5\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Rob Roy (1995) 5\n",
      "Desperado (1995) 5\n",
      "So I Married an Axe Murderer (1993) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Dumbo (1941) 5\n",
      "That Thing You Do! (1996) 5\n",
      "Ghost and the Darkness, The (1996) 5\n",
      "Alien (1979) 5\n",
      "Quiet Man, The (1952) 5\n",
      "Indiana Jones and the Last Crusade (1989) 5\n",
      "\n",
      "Using recommender  Item KNN\n",
      "\n",
      "Building recommendation model...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Best Men (1997) 5\n",
      "Galaxy of Terror (Quest) (1981) 5\n",
      "Looker (1981) 5\n",
      "Android (1982) 5\n",
      "Alien Contamination (1980) 5\n",
      "Master of the Flying Guillotine (Du bi quan wang da po xue di zi) (1975) 5\n",
      "Priceless (Hors de prix) (2006) 5\n",
      "Lassie (1994) 5\n",
      "Act of Valor (2012) 5\n",
      "Honey (2003) 5\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Full Metal Jacket (1987) 5\n",
      "Sneakers (1992) 5\n",
      "Newton Boys, The (1998) 5\n",
      "Psycho (1998) 5\n",
      "Dick Tracy (1990) 5\n",
      "Superman II (1980) 5\n",
      "Frankenstein (1931) 5\n",
      "Who Framed Roger Rabbit? (1988) 5\n",
      "Live and Let Die (1973) 5\n",
      "Green Mile, The (1999) 5\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Load up common data set for the recommender algorithms\n",
    "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
    "\n",
    "# Construct an Evaluator to, you know, evaluate them\n",
    "evaluator = Evaluator(evaluationData, rankings)\n",
    "\n",
    "\n",
    "# Item-based KNN\n",
    "ItemKNN = KNNBasic(sim_options = {'name': 'cosine', 'user_based': False})\n",
    "evaluator.AddAlgorithm(ItemKNN, \"Item KNN\")\n",
    "\n",
    "# Just make random recommendations\n",
    "Random = NormalPredictor()\n",
    "evaluator.AddAlgorithm(Random, \"Random\")\n",
    "\n",
    "# Fight!\n",
    "evaluator.Evaluate(False)\n",
    "\n",
    "evaluator.SampleTopNRecs(ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Metric Result\n",
    "| Algorithm   | RMSE    | MAE     |\n",
    "|-------------|---------|---------|\n",
    "| ContentKNN | 0.9055  | 0.6983  |\n",
    "| Random     | 1.4265  | 1.1400  |\n",
    "| SVD        | 0.8774  | 0.6741  |\n",
    "| SVD++      | 0.8721  | 0.6669  |\n",
    "| Item KNN   | 0.9788  | 0.7610  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuMF Algorithm\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r\"D:\\ITI\\Rec_Sys_Intake_45\\project_descrption\\project\\data\\ml-latest-small\\ratings.csv\")\n",
    "\n",
    "# Create mappings\n",
    "user_ids = df[\"userId\"].unique()\n",
    "item_ids = df[\"movieId\"].unique()\n",
    "\n",
    "\n",
    "df[\"rating\"] = (df[\"rating\"] - 0.5) / 4.5  # Normalize ratings to [0, 1]\n",
    "\n",
    "user_to_idx = {user: idx for idx, user in enumerate(user_ids)}\n",
    "item_to_idx = {item: idx for idx, item in enumerate(item_ids)}\n",
    "\n",
    "# Convert to indices\n",
    "df[\"user_idx\"] = df[\"userId\"].map(user_to_idx)\n",
    "df[\"item_idx\"] = df[\"movieId\"].map(item_to_idx)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create PyTorch Dataset\n",
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.LongTensor(df[\"user_idx\"].values)\n",
    "        self.items = torch.LongTensor(df[\"item_idx\"].values)\n",
    "        self.ratings = torch.FloatTensor(df[\"rating\"].values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "\n",
    "train_dataset = RatingDataset(train_df)\n",
    "test_dataset = RatingDataset(test_df)\n",
    "\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mf_dim=8, mlp_dim=32, layers=[64, 32, 16]):\n",
    "        super(NeuMF, self).__init__()\n",
    "        \n",
    "        # MF embeddings\n",
    "        self.mf_user_embedding = nn.Embedding(num_users, mf_dim)\n",
    "        self.mf_item_embedding = nn.Embedding(num_items, mf_dim)\n",
    "        \n",
    "        # MLP embeddings\n",
    "        self.mlp_user_embedding = nn.Embedding(num_users, mlp_dim)\n",
    "        self.mlp_item_embedding = nn.Embedding(num_items, mlp_dim)\n",
    "        \n",
    "        # MLP layers\n",
    "        input_size = mlp_dim * 2  # Concatenated user and item embeddings\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, layers[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Add remaining layers dynamically\n",
    "        for i in range(1, len(layers)):\n",
    "            self.mlp.add_module(f\"fc{i}\", nn.Linear(layers[i-1], layers[i]))\n",
    "            self.mlp.add_module(f\"relu{i}\", nn.ReLU())\n",
    "            self.mlp.add_module(f\"dropout{i}\", nn.Dropout(0.2))\n",
    "        \n",
    "        # Final layer\n",
    "        self.predict_layer = nn.Linear(mf_dim + layers[-1], 1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weight_()\n",
    "    \n",
    "    def _init_weight_(self):\n",
    "        nn.init.normal_(self.mf_user_embedding.weight, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.mf_item_embedding.weight, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.mlp_user_embedding.weight, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.mlp_item_embedding.weight, mean=0.0, std=0.01)\n",
    "        \n",
    "        for layer in self.mlp:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.predict_layer.weight, a=1, nonlinearity='sigmoid')\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        # MF part\n",
    "        mf_user_embedded = self.mf_user_embedding(user)\n",
    "        mf_item_embedded = self.mf_item_embedding(item)\n",
    "        mf_output = mf_user_embedded * mf_item_embedded  # element-wise product\n",
    "        \n",
    "        # MLP part\n",
    "        mlp_user_embedded = self.mlp_user_embedding(user)\n",
    "        mlp_item_embedded = self.mlp_item_embedding(item)\n",
    "        mlp_input = torch.cat([mlp_user_embedded, mlp_item_embedded], dim=-1)\n",
    "        mlp_output = self.mlp(mlp_input)\n",
    "        \n",
    "        # Concatenate MF and MLP parts\n",
    "        output = torch.cat([mf_output, mlp_output], dim=-1)\n",
    "        output = self.predict_layer(output)\n",
    "        output = torch.sigmoid(output) * 4.5 + 0.5  # Scale to [0.5, 5.0]\n",
    "        \n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "num_users = len(user_ids)\n",
    "num_items = len(item_ids)\n",
    "#model = NeuMF(num_users, num_items)\n",
    "model = NeuMF(num_users, num_items, mf_dim=16, mlp_dim=64, layers=[128, 64, 32])\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.0179\n",
      "Epoch [2/50], Train Loss: 0.0179\n",
      "Epoch [3/50], Train Loss: 0.0178\n",
      "Epoch [4/50], Train Loss: 0.0180\n",
      "Epoch [5/50], Train Loss: 0.0180\n",
      "Epoch [6/50], Train Loss: 0.0179\n",
      "Epoch [7/50], Train Loss: 0.0184\n",
      "Epoch [8/50], Train Loss: 0.0177\n",
      "Epoch [9/50], Train Loss: 0.0177\n",
      "Epoch [10/50], Train Loss: 0.0177\n",
      "Epoch [11/50], Train Loss: 0.0179\n",
      "Epoch [12/50], Train Loss: 0.0179\n",
      "Epoch [13/50], Train Loss: 0.0178\n",
      "Epoch [14/50], Train Loss: 0.0181\n",
      "Epoch [15/50], Train Loss: 0.0179\n",
      "Epoch [16/50], Train Loss: 0.0177\n",
      "Epoch [17/50], Train Loss: 0.0177\n",
      "Epoch [18/50], Train Loss: 0.0177\n",
      "Epoch [19/50], Train Loss: 0.0181\n",
      "Epoch [20/50], Train Loss: 0.0177\n",
      "Epoch [21/50], Train Loss: 0.0180\n",
      "Epoch [22/50], Train Loss: 0.0179\n",
      "Epoch [23/50], Train Loss: 0.0176\n",
      "Epoch [24/50], Train Loss: 0.0177\n",
      "Epoch [25/50], Train Loss: 0.0180\n",
      "Epoch [26/50], Train Loss: 0.0178\n",
      "Epoch [27/50], Train Loss: 0.0177\n",
      "Epoch [28/50], Train Loss: 0.0180\n",
      "Epoch [29/50], Train Loss: 0.0178\n",
      "Epoch [30/50], Train Loss: 0.0177\n",
      "Epoch [31/50], Train Loss: 0.0178\n",
      "Epoch [32/50], Train Loss: 0.0177\n",
      "Epoch [33/50], Train Loss: 0.0177\n",
      "Epoch [34/50], Train Loss: 0.0178\n",
      "Epoch [35/50], Train Loss: 0.0177\n",
      "Epoch [36/50], Train Loss: 0.0175\n",
      "Epoch [37/50], Train Loss: 0.0179\n",
      "Epoch [38/50], Train Loss: 0.0180\n",
      "Epoch [39/50], Train Loss: 0.0177\n",
      "Epoch [40/50], Train Loss: 0.0177\n",
      "Epoch [41/50], Train Loss: 0.0178\n",
      "Epoch [42/50], Train Loss: 0.0177\n",
      "Epoch [43/50], Train Loss: 0.0177\n",
      "Epoch [44/50], Train Loss: 0.0179\n",
      "Epoch [45/50], Train Loss: 0.0179\n",
      "Epoch [46/50], Train Loss: 0.0176\n",
      "Epoch [47/50], Train Loss: 0.0177\n",
      "Epoch [48/50], Train Loss: 0.0176\n",
      "Epoch [49/50], Train Loss: 0.0180\n",
      "Epoch [50/50], Train Loss: 0.0185\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (users, items, ratings) in enumerate(dataloader):\n",
    "        users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(users, items)\n",
    "        loss = criterion(outputs, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Training\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.3325\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for users, items, ratings in dataloader:\n",
    "            users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "            outputs = model(users, items)\n",
    "            total_loss += criterion(outputs, ratings).item()\n",
    "    return (total_loss / len(dataloader)) ** 0.5  # Convert MSE to RMSE\n",
    "\n",
    "test_rmse = evaluate(model, test_loader, nn.MSELoss(), device)\n",
    "print(f'Test RMSE: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 recommendations for user 85:\n",
      "1. Item ID: 920, moviename: Gone with the Wind (1939) Predicted rating: 6.98\n",
      "2. Item ID: 31658, moviename: Howl's Moving Castle (Hauru no ugoku shiro) (2004) Predicted rating: 6.17\n",
      "3. Item ID: 899, moviename: Singin' in the Rain (1952) Predicted rating: 5.99\n",
      "4. Item ID: 1090, moviename: Platoon (1986) Predicted rating: 5.73\n",
      "5. Item ID: 6615, moviename: Freddy vs. Jason (2003) Predicted rating: 5.63\n",
      "6. Item ID: 4799, moviename: It's a Mad, Mad, Mad, Mad World (1963) Predicted rating: 5.61\n",
      "7. Item ID: 2709, moviename: Muppets From Space (1999) Predicted rating: 5.57\n",
      "8. Item ID: 68237, moviename: Moon (2009) Predicted rating: 5.56\n",
      "9. Item ID: 3480, moviename: Lucas (1986) Predicted rating: 5.55\n",
      "10. Item ID: 234, moviename: Exit to Eden (1994) Predicted rating: 5.53\n"
     ]
    }
   ],
   "source": [
    "def get_top_k_recommendations(model, user_id, user_to_idx, item_ids, item_to_idx, device, k=10, rated_items=None):\n",
    "    \"\"\"\n",
    "    Get top-K recommendations for a user\n",
    "    \n",
    "    Args:\n",
    "        model: Trained NeuMF model\n",
    "        user_id: ID of the user to recommend for\n",
    "        user_to_idx: User ID to index mapping\n",
    "        item_ids: List of all item IDs in the dataset\n",
    "        item_to_idx: Item ID to index mapping\n",
    "        device: Device to run computations on\n",
    "        k: Number of recommendations to return\n",
    "        rated_items: Set of items the user has already rated (to exclude from recommendations)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert user ID to index\n",
    "    if isinstance(user_id, str):\n",
    "        user_idx = torch.LongTensor([user_to_idx[user_id]])\n",
    "    else:\n",
    "        user_idx = torch.LongTensor([user_id])\n",
    "    user_idx = user_idx.to(device)\n",
    "    \n",
    "    # Prepare all item indices\n",
    "    all_item_indices = torch.LongTensor([item_to_idx[item] for item in item_ids]).to(device)\n",
    "    \n",
    "    # Create user tensor with same length as items (for batch prediction)\n",
    "    user_indices = user_idx.repeat(len(all_item_indices))\n",
    "    \n",
    "    # Predict ratings for all items\n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_indices, all_item_indices)\n",
    "        predictions = torch.clamp(predictions, min=0.5, max=5.0)  # Clip to rating range\n",
    "    \n",
    "    # Convert predictions to numpy array\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    \n",
    "    # Create a dictionary of item IDs to predicted ratings\n",
    "    item_ratings = {item_id: pred for item_id, pred in zip(item_ids, predictions)}\n",
    "    \n",
    "    # Filter out items the user has already rated if provided\n",
    "    if rated_items is not None:\n",
    "        item_ratings = {item: rating for item, rating in item_ratings.items() \n",
    "                       if item not in rated_items}\n",
    "    \n",
    "    # Sort items by predicted rating\n",
    "    sorted_ratings = sorted(item_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-K items\n",
    "    top_k = sorted_ratings[:k]\n",
    "    \n",
    "    return top_k\n",
    "\n",
    "# Example usage:\n",
    "movie_df = pd.read_csv(r\"D:\\ITI\\Rec_Sys_Intake_45\\project_descrption\\project\\data\\ml-latest-small\\movies.csv\")\n",
    "\n",
    "# First, get the items the user has already rated (to exclude them)\n",
    "user_id = 85  # Example user ID\n",
    "rated_items = set(df[df[\"userId\"] == user_id][\"movieId\"].values)\n",
    "\n",
    "# Get top 10 recommendations\n",
    "top_k = get_top_k_recommendations(model, user_id, user_to_idx, item_ids, item_to_idx, device, \n",
    "                                 k=10, rated_items=rated_items)\n",
    "\n",
    "print(f\"Top 10 recommendations for user {user_id}:\")\n",
    "for i, (item_id, predicted_rating) in enumerate(top_k, 1):\n",
    "    movie_name = movie_df[movie_df[\"movieId\"] == item_id][\"title\"].values[0]  \n",
    "    print(f\"{i}. Item ID: {item_id}, moviename: {movie_name} Predicted rating: {predicted_rating* 4.5 + 0.5:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating: 2.7988\n"
     ]
    }
   ],
   "source": [
    "def predict_rating(model, user_id, item_id, user_to_idx, item_to_idx, device):\n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(user_id, str):\n",
    "        user_idx = torch.LongTensor([user_to_idx[user_id]])\n",
    "    else:\n",
    "        user_idx = torch.LongTensor([user_id])\n",
    "    \n",
    "    if isinstance(item_id, str):\n",
    "        item_idx = torch.LongTensor([item_to_idx[item_id]])\n",
    "    else:\n",
    "        item_idx = torch.LongTensor([item_id])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        user_idx = user_idx.to(device)\n",
    "        item_idx = item_idx.to(device)\n",
    "        prediction = model(user_idx, item_idx)\n",
    "        prediction = torch.clamp(prediction, min=0.5, max=5.0)  # Clip to rating range\n",
    "    \n",
    "    return prediction.item()\n",
    "\n",
    "# Example prediction\n",
    "user_id = 431  # or use original user ID if it's a string\n",
    "item_id = 4730  # or use original item ID if it's a string\n",
    "prediction = predict_rating(model, user_id, item_id, user_to_idx, item_to_idx, device)\n",
    "prediction = prediction * 4.5 + 0.5\n",
    "print(f'Predicted rating: {prediction:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchWrapper:\n",
    "    \"\"\"Wrapper to make PyTorch model compatible with Surprise's interface\"\"\"\n",
    "    def __init__(self, model, user_to_idx, item_to_idx, device):\n",
    "        self.model = model\n",
    "        self.user_to_idx = user_to_idx\n",
    "        self.item_to_idx = item_to_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def predict(self, uid, iid, r_ui=None):\n",
    "        # Convert string IDs to indices\n",
    "        try:\n",
    "            user_idx = torch.LongTensor([self.user_to_idx[str(uid)]])\n",
    "            item_idx = torch.LongTensor([self.item_to_idx[str(iid)]])\n",
    "        except KeyError as e:\n",
    "            # Return neutral prediction if user/item not in model\n",
    "            return Prediction(uid, iid, r_ui, 3.0, {'was_impossible': True})\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            user_idx = user_idx.to(self.device)\n",
    "            item_idx = item_idx.to(self.device)\n",
    "            prediction = self.model(user_idx, item_idx)\n",
    "            prediction = torch.clamp(prediction, min=0.5, max=5.0).item()\n",
    "        \n",
    "        # Scale prediction if needed (remove if already scaled)\n",
    "        prediction = prediction * 4.5 + 0.5\n",
    "        \n",
    "        return Prediction(uid, iid, r_ui, prediction, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybird System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating  SVD ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  ContentKNN ...\n",
      "Evaluating accuracy...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  8775\n",
      "100  of  8775\n",
      "200  of  8775\n",
      "300  of  8775\n",
      "400  of  8775\n",
      "500  of  8775\n",
      "600  of  8775\n",
      "700  of  8775\n",
      "800  of  8775\n",
      "900  of  8775\n",
      "1000  of  8775\n",
      "1100  of  8775\n",
      "1200  of  8775\n",
      "1300  of  8775\n",
      "1400  of  8775\n",
      "1500  of  8775\n",
      "1600  of  8775\n",
      "1700  of  8775\n",
      "1800  of  8775\n",
      "1900  of  8775\n",
      "2000  of  8775\n",
      "2100  of  8775\n",
      "2200  of  8775\n",
      "2300  of  8775\n",
      "2400  of  8775\n",
      "2500  of  8775\n",
      "2600  of  8775\n",
      "2700  of  8775\n",
      "2800  of  8775\n",
      "2900  of  8775\n",
      "3000  of  8775\n",
      "3100  of  8775\n",
      "3200  of  8775\n",
      "3300  of  8775\n",
      "3400  of  8775\n",
      "3500  of  8775\n",
      "3600  of  8775\n",
      "3700  of  8775\n",
      "3800  of  8775\n",
      "3900  of  8775\n",
      "4000  of  8775\n",
      "4100  of  8775\n",
      "4200  of  8775\n",
      "4300  of  8775\n",
      "4400  of  8775\n",
      "4500  of  8775\n",
      "4600  of  8775\n",
      "4700  of  8775\n",
      "4800  of  8775\n",
      "4900  of  8775\n",
      "5000  of  8775\n",
      "5100  of  8775\n",
      "5200  of  8775\n",
      "5300  of  8775\n",
      "5400  of  8775\n",
      "5500  of  8775\n",
      "5600  of  8775\n",
      "5700  of  8775\n",
      "5800  of  8775\n",
      "5900  of  8775\n",
      "6000  of  8775\n",
      "6100  of  8775\n",
      "6200  of  8775\n",
      "6300  of  8775\n",
      "6400  of  8775\n",
      "6500  of  8775\n",
      "6600  of  8775\n",
      "6700  of  8775\n",
      "6800  of  8775\n",
      "6900  of  8775\n",
      "7000  of  8775\n",
      "7100  of  8775\n",
      "7200  of  8775\n",
      "7300  of  8775\n",
      "7400  of  8775\n",
      "7500  of  8775\n",
      "7600  of  8775\n",
      "7700  of  8775\n",
      "7800  of  8775\n",
      "7900  of  8775\n",
      "8000  of  8775\n",
      "8100  of  8775\n",
      "8200  of  8775\n",
      "8300  of  8775\n",
      "8400  of  8775\n",
      "8500  of  8775\n",
      "8600  of  8775\n",
      "8700  of  8775\n",
      "...done.\n",
      "Analysis complete.\n",
      "Evaluating  Hybrid ...\n",
      "Evaluating accuracy...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  8775\n",
      "100  of  8775\n",
      "200  of  8775\n",
      "300  of  8775\n",
      "400  of  8775\n",
      "500  of  8775\n",
      "600  of  8775\n",
      "700  of  8775\n",
      "800  of  8775\n",
      "900  of  8775\n",
      "1000  of  8775\n",
      "1100  of  8775\n",
      "1200  of  8775\n",
      "1300  of  8775\n",
      "1400  of  8775\n",
      "1500  of  8775\n",
      "1600  of  8775\n",
      "1700  of  8775\n",
      "1800  of  8775\n",
      "1900  of  8775\n",
      "2000  of  8775\n",
      "2100  of  8775\n",
      "2200  of  8775\n",
      "2300  of  8775\n",
      "2400  of  8775\n",
      "2500  of  8775\n",
      "2600  of  8775\n",
      "2700  of  8775\n",
      "2800  of  8775\n",
      "2900  of  8775\n",
      "3000  of  8775\n",
      "3100  of  8775\n",
      "3200  of  8775\n",
      "3300  of  8775\n",
      "3400  of  8775\n",
      "3500  of  8775\n",
      "3600  of  8775\n",
      "3700  of  8775\n",
      "3800  of  8775\n",
      "3900  of  8775\n",
      "4000  of  8775\n",
      "4100  of  8775\n",
      "4200  of  8775\n",
      "4300  of  8775\n",
      "4400  of  8775\n",
      "4500  of  8775\n",
      "4600  of  8775\n",
      "4700  of  8775\n",
      "4800  of  8775\n",
      "4900  of  8775\n",
      "5000  of  8775\n",
      "5100  of  8775\n",
      "5200  of  8775\n",
      "5300  of  8775\n",
      "5400  of  8775\n",
      "5500  of  8775\n",
      "5600  of  8775\n",
      "5700  of  8775\n",
      "5800  of  8775\n",
      "5900  of  8775\n",
      "6000  of  8775\n",
      "6100  of  8775\n",
      "6200  of  8775\n",
      "6300  of  8775\n",
      "6400  of  8775\n",
      "6500  of  8775\n",
      "6600  of  8775\n",
      "6700  of  8775\n",
      "6800  of  8775\n",
      "6900  of  8775\n",
      "7000  of  8775\n",
      "7100  of  8775\n",
      "7200  of  8775\n",
      "7300  of  8775\n",
      "7400  of  8775\n",
      "7500  of  8775\n",
      "7600  of  8775\n",
      "7700  of  8775\n",
      "7800  of  8775\n",
      "7900  of  8775\n",
      "8000  of  8775\n",
      "8100  of  8775\n",
      "8200  of  8775\n",
      "8300  of  8775\n",
      "8400  of  8775\n",
      "8500  of  8775\n",
      "8600  of  8775\n",
      "8700  of  8775\n",
      "...done.\n",
      "Analysis complete.\n",
      "\n",
      "\n",
      "Algorithm  RMSE       MAE       \n",
      "SVD        0.8695     0.6652    \n",
      "ContentKNN 0.9055     0.6983    \n",
      "Hybrid     0.8622     0.6615    \n",
      "\n",
      "Legend:\n",
      "\n",
      "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
      "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
      "\n",
      "Using recommender  SVD\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Life Is Beautiful (La Vita Ã¨ bella) (1997) 4.446208060348329\n",
      "Streetcar Named Desire, A (1951) 4.393978112476887\n",
      "Day of the Doctor, The (2013) 4.374895319430759\n",
      "Cinema Paradiso (Nuovo cinema Paradiso) (1989) 4.356625028637217\n",
      "In the Name of the Father (1993) 4.336572736687317\n",
      "Dogville (2003) 4.320924952787669\n",
      "Sunset Blvd. (a.k.a. Sunset Boulevard) (1950) 4.316153035740014\n",
      "Guess Who's Coming to Dinner (1967) 4.30528891389759\n",
      "Sound of Music, The (1965) 4.301549211074392\n",
      "Great Escape, The (1963) 4.3007723710414165\n",
      "\n",
      "Using recommender  ContentKNN\n",
      "\n",
      "Building recommendation model...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  9724\n",
      "100  of  9724\n",
      "200  of  9724\n",
      "300  of  9724\n",
      "400  of  9724\n",
      "500  of  9724\n",
      "600  of  9724\n",
      "700  of  9724\n",
      "800  of  9724\n",
      "900  of  9724\n",
      "1000  of  9724\n",
      "1100  of  9724\n",
      "1200  of  9724\n",
      "1300  of  9724\n",
      "1400  of  9724\n",
      "1500  of  9724\n",
      "1600  of  9724\n",
      "1700  of  9724\n",
      "1800  of  9724\n",
      "1900  of  9724\n",
      "2000  of  9724\n",
      "2100  of  9724\n",
      "2200  of  9724\n",
      "2300  of  9724\n",
      "2400  of  9724\n",
      "2500  of  9724\n",
      "2600  of  9724\n",
      "2700  of  9724\n",
      "2800  of  9724\n",
      "2900  of  9724\n",
      "3000  of  9724\n",
      "3100  of  9724\n",
      "3200  of  9724\n",
      "3300  of  9724\n",
      "3400  of  9724\n",
      "3500  of  9724\n",
      "3600  of  9724\n",
      "3700  of  9724\n",
      "3800  of  9724\n",
      "3900  of  9724\n",
      "4000  of  9724\n",
      "4100  of  9724\n",
      "4200  of  9724\n",
      "4300  of  9724\n",
      "4400  of  9724\n",
      "4500  of  9724\n",
      "4600  of  9724\n",
      "4700  of  9724\n",
      "4800  of  9724\n",
      "4900  of  9724\n",
      "5000  of  9724\n",
      "5100  of  9724\n",
      "5200  of  9724\n",
      "5300  of  9724\n",
      "5400  of  9724\n",
      "5500  of  9724\n",
      "5600  of  9724\n",
      "5700  of  9724\n",
      "5800  of  9724\n",
      "5900  of  9724\n",
      "6000  of  9724\n",
      "6100  of  9724\n",
      "6200  of  9724\n",
      "6300  of  9724\n",
      "6400  of  9724\n",
      "6500  of  9724\n",
      "6600  of  9724\n",
      "6700  of  9724\n",
      "6800  of  9724\n",
      "6900  of  9724\n",
      "7000  of  9724\n",
      "7100  of  9724\n",
      "7200  of  9724\n",
      "7300  of  9724\n",
      "7400  of  9724\n",
      "7500  of  9724\n",
      "7600  of  9724\n",
      "7700  of  9724\n",
      "7800  of  9724\n",
      "7900  of  9724\n",
      "8000  of  9724\n",
      "8100  of  9724\n",
      "8200  of  9724\n",
      "8300  of  9724\n",
      "8400  of  9724\n",
      "8500  of  9724\n",
      "8600  of  9724\n",
      "8700  of  9724\n",
      "8800  of  9724\n",
      "8900  of  9724\n",
      "9000  of  9724\n",
      "9100  of  9724\n",
      "9200  of  9724\n",
      "9300  of  9724\n",
      "9400  of  9724\n",
      "9500  of  9724\n",
      "9600  of  9724\n",
      "9700  of  9724\n",
      "...done.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Pinocchio (1940) 5\n",
      "James and the Giant Peach (1996) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Escape to Witch Mountain (1975) 5\n",
      "Winnie the Pooh and the Blustery Day (1968) 5\n",
      "Three Caballeros, The (1945) 5\n",
      "Sword in the Stone, The (1963) 5\n",
      "Pete's Dragon (1977) 5\n",
      "Bedknobs and Broomsticks (1971) 5\n",
      "Alice in Wonderland (1951) 5\n",
      "\n",
      "Using recommender  Hybrid\n",
      "\n",
      "Building recommendation model...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  9724\n",
      "100  of  9724\n",
      "200  of  9724\n",
      "300  of  9724\n",
      "400  of  9724\n",
      "500  of  9724\n",
      "600  of  9724\n",
      "700  of  9724\n",
      "800  of  9724\n",
      "900  of  9724\n",
      "1000  of  9724\n",
      "1100  of  9724\n",
      "1200  of  9724\n",
      "1300  of  9724\n",
      "1400  of  9724\n",
      "1500  of  9724\n",
      "1600  of  9724\n",
      "1700  of  9724\n",
      "1800  of  9724\n",
      "1900  of  9724\n",
      "2000  of  9724\n",
      "2100  of  9724\n",
      "2200  of  9724\n",
      "2300  of  9724\n",
      "2400  of  9724\n",
      "2500  of  9724\n",
      "2600  of  9724\n",
      "2700  of  9724\n",
      "2800  of  9724\n",
      "2900  of  9724\n",
      "3000  of  9724\n",
      "3100  of  9724\n",
      "3200  of  9724\n",
      "3300  of  9724\n",
      "3400  of  9724\n",
      "3500  of  9724\n",
      "3600  of  9724\n",
      "3700  of  9724\n",
      "3800  of  9724\n",
      "3900  of  9724\n",
      "4000  of  9724\n",
      "4100  of  9724\n",
      "4200  of  9724\n",
      "4300  of  9724\n",
      "4400  of  9724\n",
      "4500  of  9724\n",
      "4600  of  9724\n",
      "4700  of  9724\n",
      "4800  of  9724\n",
      "4900  of  9724\n",
      "5000  of  9724\n",
      "5100  of  9724\n",
      "5200  of  9724\n",
      "5300  of  9724\n",
      "5400  of  9724\n",
      "5500  of  9724\n",
      "5600  of  9724\n",
      "5700  of  9724\n",
      "5800  of  9724\n",
      "5900  of  9724\n",
      "6000  of  9724\n",
      "6100  of  9724\n",
      "6200  of  9724\n",
      "6300  of  9724\n",
      "6400  of  9724\n",
      "6500  of  9724\n",
      "6600  of  9724\n",
      "6700  of  9724\n",
      "6800  of  9724\n",
      "6900  of  9724\n",
      "7000  of  9724\n",
      "7100  of  9724\n",
      "7200  of  9724\n",
      "7300  of  9724\n",
      "7400  of  9724\n",
      "7500  of  9724\n",
      "7600  of  9724\n",
      "7700  of  9724\n",
      "7800  of  9724\n",
      "7900  of  9724\n",
      "8000  of  9724\n",
      "8100  of  9724\n",
      "8200  of  9724\n",
      "8300  of  9724\n",
      "8400  of  9724\n",
      "8500  of  9724\n",
      "8600  of  9724\n",
      "8700  of  9724\n",
      "8800  of  9724\n",
      "8900  of  9724\n",
      "9000  of  9724\n",
      "9100  of  9724\n",
      "9200  of  9724\n",
      "9300  of  9724\n",
      "9400  of  9724\n",
      "9500  of  9724\n",
      "9600  of  9724\n",
      "9700  of  9724\n",
      "...done.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Paths of Glory (1957) 4.554727750671657\n",
      "Streetcar Named Desire, A (1951) 4.551372589444486\n",
      "Spirited Away (Sen to Chihiro no kamikakushi) (2001) 4.538159983888552\n",
      "Casablanca (1942) 4.526133493165087\n",
      "Philadelphia Story, The (1940) 4.519257768348955\n",
      "Bridge on the River Kwai, The (1957) 4.5152839236925395\n",
      "Wizard of Oz, The (1939) 4.5091593425282115\n",
      "High Noon (1952) 4.507572889366134\n",
      "Hustler, The (1961) 4.480015441611847\n",
      "12 Angry Men (1957) 4.478734586189739\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Load up common data set for the recommender algorithms\n",
    "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
    "\n",
    "# Construct an Evaluator to, you know, evaluate them\n",
    "evaluator = Evaluator(evaluationData, rankings)\n",
    "\n",
    "#Simple RBM\n",
    "SVDPlusPlus = SVDpp()\n",
    "#Content\n",
    "ContentKNN = ContentKNNAlgorithm()\n",
    "\n",
    "#Combine them\n",
    "Hybrid = HybridAlgorithm([SVDPlusPlus, ContentKNN], [0.5, 0.5])\n",
    "\n",
    "evaluator.AddAlgorithm(SVDPlusPlus, \"SVD\")\n",
    "evaluator.AddAlgorithm(ContentKNN, \"ContentKNN\")\n",
    "evaluator.AddAlgorithm(Hybrid, \"Hybrid\")\n",
    "\n",
    "# Fight!\n",
    "evaluator.Evaluate(False)\n",
    "\n",
    "evaluator.SampleTopNRecs(ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm   | RMSE    | MAE     |\n",
    "|-------------|---------|---------|\n",
    "| SVD++         | 0.8695  | 0.6652  |\n",
    "| ContentKNN  | 0.9055  | 0.6983  |\n",
    "| Hybrid      | 0.8622  | 0.6615  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "PyTorch         RMSE: 1.1616, MAE: 0.9427\n",
      "SVD++           RMSE: 0.8763, MAE: 0.6711\n",
      "ItemKNN         RMSE: 0.9889, MAE: 0.7673\n",
      "Hybrid          RMSE: 0.9507, MAE: 0.7630\n",
      "\n",
      "Example Hybrid Prediction for user 431, item 4730:\n",
      "PyTorch: 3.00\n",
      "SVD++: 2.83\n",
      "ItemKNN: 3.50\n",
      "Hybrid: 3.10\n"
     ]
    }
   ],
   "source": [
    "from surprise import Prediction\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "\n",
    "pytorch_model = PyTorchWrapper(model, user_to_idx, item_to_idx, device)\n",
    "SVDPlusPlus = SVDpp()\n",
    "ItemKNN = KNNBasic(sim_options={'name': 'cosine', 'user_based': False})\n",
    "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
    "# Hybrid prediction function that combines all three\n",
    "def hybrid_predict(testset, weights=[0.2, 0.4, 0.4]):\n",
    "    predictions = []\n",
    "    for uid, iid, true_r in testset:\n",
    "        try:\n",
    "            pred_pytorch = pytorch_model.predict(uid, iid).est\n",
    "            pred_svd = SVDPlusPlus.predict(uid, iid).est\n",
    "            pred_knn = ItemKNN.predict(uid, iid).est\n",
    "            \n",
    "            hybrid_est = (weights[0]*pred_pytorch + \n",
    "                         weights[1]*pred_svd + \n",
    "                         weights[2]*pred_knn)\n",
    "            \n",
    "            predictions.append(Prediction(uid, iid, true_r, hybrid_est, {}))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping prediction for {uid}, {iid}: {str(e)}\")\n",
    "            continue\n",
    "    return predictions\n",
    "\n",
    "# Train the Surprise algorithms\n",
    "trainset, testset = surprise_train_test_split(evaluationData, test_size=0.25)\n",
    "SVDPlusPlus.fit(trainset)\n",
    "ItemKNN.fit(trainset)\n",
    "\n",
    "# Generate hybrid predictions\n",
    "\n",
    "hybrid_preds = hybrid_predict(testset)\n",
    "\n",
    "# Evaluate\n",
    "def print_metrics(predictions, name):\n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    mae = accuracy.mae(predictions, verbose=False)\n",
    "    print(f\"{name:<15} RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "print_metrics([pytorch_model.predict(uid, iid, r) for (uid, iid, r) in testset], \"PyTorch\")\n",
    "print_metrics([SVDPlusPlus.predict(uid, iid, r) for (uid, iid, r) in testset], \"SVD++\")\n",
    "print_metrics([ItemKNN.predict(uid, iid, r) for (uid, iid, r) in testset], \"ItemKNN\")\n",
    "print_metrics(hybrid_preds, \"Hybrid\")\n",
    "\n",
    "# Example prediction\n",
    "user_id = \"431\"  # Using original user ID\n",
    "item_id = \"4730\"  # Using original item ID\n",
    "print(f\"\\nExample Hybrid Prediction for user {user_id}, item {item_id}:\")\n",
    "print(f\"PyTorch: {pytorch_model.predict(user_id, item_id).est:.2f}\")\n",
    "print(f\"SVD++: {SVDPlusPlus.predict(user_id, item_id).est:.2f}\")\n",
    "print(f\"ItemKNN: {ItemKNN.predict(user_id, item_id).est:.2f}\")\n",
    "print(f\"Hybrid: {hybrid_predict([(user_id, item_id, None)])[0].est:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Hybrid Top 10 Recommendations for User 85:\n",
      "Item 33794: Predicted rating 5.00\n",
      "Item 92259: Predicted rating 5.00\n",
      "Item 106696: Predicted rating 4.50\n",
      "Item 69406: Predicted rating 4.50\n",
      "Item 51705: Predicted rating 4.50\n",
      "Item 68954: Predicted rating 4.00\n",
      "Item 6942: Predicted rating 4.00\n",
      "Item 95167: Predicted rating 4.00\n",
      "Item 588: Predicted rating 4.00\n",
      "Item 7375: Predicted rating 4.00\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Load data\n",
    "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
    "\n",
    "# Initialize algorithms\n",
    "SVDPlusPlus = SVDpp()\n",
    "ItemKNN = KNNBasic(sim_options={'name': 'cosine', 'user_based': False})\n",
    "trainset, testset = train_test_split(evaluationData, test_size=0.25)\n",
    "\n",
    "# Train both algorithms\n",
    "SVDPlusPlus.fit(trainset)\n",
    "ItemKNN.fit(trainset)\n",
    "\n",
    "\n",
    "\n",
    "# Function to get weighted average predictions\n",
    "pytorch_model = PyTorchWrapper(model, user_to_idx, item_to_idx, device)\n",
    "\n",
    "# Hybrid prediction function\n",
    "def get_hybrid_predictions(algo1, algo2, pytorch_model, testset, weights=[0.2, 0.4, 0.4]):\n",
    "    predictions = []\n",
    "    for uid, iid, true_r in testset:\n",
    "        try:\n",
    "            pred_pytorch = pytorch_model.predict(uid, iid).est\n",
    "            pred_svd = SVDPlusPlus.predict(uid, iid).est\n",
    "            pred_knn = ItemKNN.predict(uid, iid).est\n",
    "            \n",
    "            hybrid_est = (weights[0]*pred_pytorch + \n",
    "                         weights[1]*pred_svd + \n",
    "                         weights[2]*pred_knn)\n",
    "            \n",
    "            predictions.append(Prediction(uid, iid, true_r, hybrid_est, {}))\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping prediction for {uid}, {iid}: {str(e)}\")\n",
    "            continue\n",
    "    return predictions\n",
    "\n",
    "# Get predictions (40% SVD++, 30% ItemKNN, 30% PyTorch)\n",
    "hybrid_preds = get_hybrid_predictions(SVDPlusPlus, ItemKNN, pytorch_model, testset)\n",
    "\n",
    "# Top-N recommendations function\n",
    "def get_top_n_hybrid(user_id, hybrid_preds, n=10):\n",
    "    user_preds = [pred for pred in hybrid_preds if pred[0] == user_id]\n",
    "    user_preds.sort(key=lambda x: x[2], reverse=True)\n",
    "    return user_preds[:n]\n",
    "\n",
    "\n",
    "# Example: Get top 10 hybrid recommendations for user 1\n",
    "top_hybrid = get_top_n_hybrid('10', hybrid_preds)\n",
    "print(\"Hybrid Top 10 Recommendations for User 85:\")\n",
    "for item in top_hybrid:\n",
    "    print(f\"Item {item[1]}: Predicted rating {item[2]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1b7df873c2ccebe52f2c02746e96a567ab718f047b2affb3d9b03db2b6dece1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
